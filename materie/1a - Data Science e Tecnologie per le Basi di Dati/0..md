# Progettazione Data Warehouse
## Schema dei fatti
1. Identifica il **fatto** o i fatti di interesse e individua le *misure* richieste.
2. Definisci le **dimensioni** associate, stabilendo i gradi di *gerarchia*.
## Schema logico
1. Analizza prima le **query**.
2. Ad ogni **dimensione** corrisponde una *tabella*.
3. Trasforma gli **attributi multipli**.
## Query
### Estensioni SQL
#### Window
``` sql
SELECT città, mese,
	AVG(importo) OVER (PARTITION BY città,
					   ORDER BY mese,    -- Ordinamento
					   ROWS 2 PRECEDING) -- Finestra di aggregazione
					   AS MediaMobile
FROM vendite
GROUP BY città, mese
```

Gli attributi che compaiono nella *finestra di aggregazione* **DEVONO** essere presenti nella  `GROUP BY`.

Per il calcolo di aggregati sulla finestra `SUM(SUM(attributo)) OVER < Partizione >`, dato che il `SUM` più interno è riferito alla `GROUP BY`, mentre l'altro alla partizione.

*Ordinamento* e *finestra di aggregazione* opzionali. La finestra può essere:
- A livello **fisico** (mediante conteggio delle righe)
	- tra un estremo *inferiore* e la riga *corrente* `ROWS 2 PRECEDING`.
	- tra un estremo *inferiore* e uno *superiore* `ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING` oppure `ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING`.
	- tra *l'inizio* o *la fine* della partizione e la riga *corrente* `ROWS UNBOUNDED PRECEDING/FOLLOWING`.
- A livello **logico** (mediante intervallo attorno alla chiave di ordinamento)
	- si utilizza il costrutto range con la sintassi del livello fisico `RANGE 2 MONTH/DAY/YEAR/WEEK PRECEDING`.
	- è necessario definire la distanzala distanza tra gli estremi dell'intervallo e il valore corrente di **ordinamento**.
	- utile per dati sparsi, che hanno interruzioni di sequenza.
	- *non* è possibile specificare più di una chiave di ordinamento e la chiave può essere solo numerica o una data.

#### Ranking
``` sql
SELECT città, mese
	<FUNZIONE> OVER (<FINESTRA>)
```

- `RANK()` calcola la posizione di un valore all'interno di una **partizione**, lasciando intervalli *vuoti* alla presenza di pari merito.
- `DENSERANK()` come RANK() ma non lascia intervalli vuoti.
- `ROW_NUMBER()` assegna un numero unico ad ogni riga della **partizione**.
- `CUME_DIST()` in una partizione di N dati corrisponde al numero di valori che *precedono* o hanno lo *stesso* valore assunto dal campo di ordinamento nella riga, diviso N
- `NTILE(n)` divide una partizione in n sottogruppi, ognuno con lo stesso numero di *record*. Ad ogni sottogruppo è associato un numero identificativo.

## Viste Materializzate
``` sql
CREATE TABLE NOME(
	nome_attributo <TIPO> <NOT NULL>,
	...
	PRIMARY KEY(lista_attributi)
);
```

1. Osservare il carico di lavoro
	- Predicati di **selezione**.
	- Attributi di **group by**.
	- Funzioni **aggregate**.
2. Individua la lista che rappresenta il *denominatore comune* di:
	- Attributi di selezione e aggregati richiesti.
	- Elementi delle group by di gerarchia più bassa.
	- *NOTA*: Non includere condizioni di selezione.
3. Realizza la **query** necessaria per popolare la vista materializzata.

# Data Mining
## Associazione
(tabella di confusione)

Correlazione tra dati, misura la relazione lineare tra 2 dati.

`A,B => C `
- A e B sono gli item del body.
- C sono gli item del head.
- la freccia indica **co-occorrenza**
	- i concetti A e B sono correlati al concetto C.

- **Support count (#)** = frequenza di occorrenza di un itemset.
- **Support (sup)** = frazione di transazioni che contengono l'itemset.
- **Frequent Itemset** = se il suo supporto è maggiore o uguale ad una certa soglia (minsup).
- **Confidenza** = data l'associazione A=>B allora la frequenza di B nelle transazioni contenenti A vale $\frac{sup(A,B)}{sup(A)}$
	- probabilità condizionale di trovare B avendo trovato A.
	- "forza" della "=>" .

**Itemset frequente massimale** = se nessuno dei suoi *superset immediati* è frequente.

**Itemset chiuso** = se nessuno dei suoi superset ha lo stesso supporto dell'itemset.

Tutti i **massimali** sono anche **chiusi**.

Considerando A => B:
	**correlazione** (o *lift*) = rapporto tra *confidenza* di una relazione e *supporto* di B.
		- **Indipendenza statistica** se valore = 1.
		- **Correlazione positiva** se valore > 1.
		- **Correlazione negativa** se valore < 1.
- Vale anche il contrario

### Apriori
n+1 scan. 2 step principali:
1. **Generazione candidati**.
	1. Si generano i candidati di *lunghezza k+1* attraverso il join di itemset frequenti di lunghezza k.
	2. Si applica il *principio a priori* e scarto gli itemset di lunghezza k+1 che contengono almeno un k-itemset *non frequente*.
2. **Generazione degli itemset frequenti**.
	1. Scan del DB per ottenere il supporto dei candidati k+1.
	2. Elimina i candidati sotto minsup.
3. **Aumenta k e ripeti**.

### Frequent Pattern Growth
2 scan. Step principali:
1. **Costruisci Header table**
	- Conta il supporto degli item ed elimina gli item con supporto inferiore a *minsup*.
	- Tabella con gli item e il loro supporto, in ordine *decrescente*.
2. **Costruisci FP-Tree**
	- Scansione del DB e per ogni *transazione* ordina gli item dei *subset* secondo la *header table*.
	- *ES.* Se il supporto di b è maggiore di quello di a, le transazioni {a,b} vengono inserite come {b,a}.
	- Si parte da una struttura ad **albero** con un nodo vuoto come radice.
	- Segui il percorso definito dalla *transazione*:
		- Se non è presente un nodo viene creato e assegnato il valore 1.
		- Se è già presente aumenta il valore di 1.
3. **Costruisci i-CPB (item Conditional Pattern Base) per ogni item**
	- Scan della *header table* a partire dal basso.
	- Individua tutte le occorrenze dell'item i nel *FP-Tree*.
	- Risalgo l'albero fino alla radice ed estraggo l'itemset senza i.
	- Il supporto dell'itemset è pari al valore di i nell'albero.
4. **Applico l'algoritmo ricorsivamente ad ogni CPB**
	- Ottengo CPB *composti* (x-CPB --> xy-CPB --> xyz-CPB).

## Classificazione
### Alberi di decisione
Diversi algoritmi per costruirne uno, analizziamo algoritmo di *Hunt*
	- Se il dataset contiene record che appartengono a più classi:
		- Seleziona il miglior attributo A sul quale splittare il dataset e crea il nodo A.
		- Dividi il dataset in sottoinsieme applica ricorsivamente la procedura ad ogni sottoinsieme.
	- Se il dataset contiene record che appartengono alla **stessa classe** $y_t$:
		- Allora il nodo è una foglia, nominata $y_t$.
	- Se il dataset è vuoto:
		- allora il nodo è una foglia, chiamato default ($y_d$).

Adotta strategia *greedy*:
	- Si sceglie ad ogni step un ottimo locale.

Gli attributi vengono scelti in modo da generare partizioni più **omogenee** possibili:
	- Stessi valori di classi.
	- Viene misurato tramite l'*impurità*.

#### Indice GINI
per un nodo t:
$$GINI(t) = 1 - \sum{[p(j|t)]^2}$$

Con $p(j|t)$ uguale alla frequenza della classe j nel nodo t:
	- **Purezza totale** -> gini = 0.
	- **Impurità massima** -> gini = $1 - 1/nc$ con nc = numero classi.
		- I record sono egualmente distribuiti tra tutte le classi.

Per splittare in base al GINI index:
$$GINIsplit = \sum_i^k{\frac{n_i}{n} GINI(i)}$$

Con i che va da 1 a k = numero partizioni
	- ni = numero di record al figlio i.
	- n = numero di record al nodo p.
- Misura la "qualità" di uno split.

#### Random forest
Dato un dataset **D** con **n** istanze con **p** attributi:
- per b = 1, ..., B
	- Genero sottoinsieme $D_b$ e genero albero di decisione su $D_b$
	- $m = \sqrt{p}$ attributi random
	- Viene calcolato lo split migliore tra tutte gli $m$ attributi
- La classe viene assegnata tra le predizioni B

### k-nearest Neighbor
A partire da un insieme di record classificati, predico la classe di un nuovo caso in base alla distanza dagli altri record.

Necessita:
- Un insieme di record.
- Distanza metrica per calcolare la distanza tra i record.
- Il valore di k, il numero di vicini più prossimi da recuperare.

Per classificare un record sconosciuto:
- Computa la distanza dagli altri training records.
- Identifica i k vicini più prossimi.
- Usa etichette di classe dei vicini prossimi per determinare la classe del record sconosciuto.

### Classificazione bayesiana
- C = qualsiasi label di classe.
- X = < x1,...,xk > record da classificare.

1. Computa P(C|X) per tutte le classi (Probabilità che il record X appartenga a C).
2. Assegna X alla classe con il P(C|X) massimale.

Applica il teorema di Bayes:
$$ P(C|X) = P(X|C) * P(C) / P(X)$$

- P(X) costante per tutti C
- P(C) probabilità a priori di C = Nc/N

## Clustering
### k-means
1. Seleziona k punti come centroidi di partenza.
2. **do**
3. Forma K cluster assegnando tutti i punti ai centroidi più vicini.
4. Ricalcola il centroide all'interno di ogni cluster.
5. **while** i centroidi non cambiano più.

k * n calcoli ad ogni iterazione.

**Bisecting k-means**
	1. Inizializza lista di cluster con un cluster che contiene tutti i punti.
	2. **do**
	3. Seleziona un cluster dalla lista.
	4. **for** i = 1 **to** numero_iterazioni.
	5. Dividi il cluster selezionato in 2 utilizzando k-means.
	6. **end for**
	7. Aggiungi i 2 cluster con il SSE più basso alla lista dei cluster.
	8. **while** la lista dei cluster contiene k cluster.

### Clustering Gerarchico
2 tipi principali:
- **Agglomerativo**
	- Inizia con i punti come cluster individuali.
	- Ad ogni step merge della coppia di cluster più vicini finchè non rimangono k cluster.
- **Divisivo**
	- Inizia con un cluster contenente tutti i punti
	- Ad ogni step dividi il cluster finchè non non rimangono k cluster.

Gli algoritmi gerarchici usano matrice di distanza.

|     | p1  | p2  | p3  | p4  | p5  |
| --- | --- | --- | --- | --- | --- |
| p1  |     |     |     |     |     |
| p2  |     |     |     |     |     |
| p3  |     |     |     |     |     |
| p4  |     |     |     |     |     |
| p5  |     |     |     |     |     |

Quando si effetua l'unione tra due cluster si sostituiscono le righe e le colonne dei cluster coinvolti.

# Ottimizzazione
## Metodi di accesso
L'accesso dai dati può esser fatto in modo indicizzato o tramite *full table scan*. 

**Full Table Scan**
- Legge tutte le righe di una tabella, i blocchi sono letti in maniera sequenziale.
- Letture multiblocco per velocizzare il processo.

L'uso di un indice è consigliato se:
- Ho a che fare con una tabella contenente almeno 10^4 record.
- La tabella è sottoposta ad un *predicato selettivo* (fattore di riduzione 1/10, 1/20).

### Strutture ad albero
Forniscono accesso diretto alla base dati basato sul valore del campo key.

Un nodo radice, diversi nodi intermedi con fan-out elevato.
Le foglie forniscono accesso ai dati:
- **Clustered**
	- Le tuple sono contenute nei nodi foglia.
- **Unclustered**
	- Le foglie contengono puntatori fisici ai dati.

**B-tree (balanced tree)**
- Le pagine possono essere raggiunte solo attraverso i valori key visitando l'albero.

**B+-tree**
- Fornisce una struttora linkata, permettendo accesso sequenziale nell'ordine di sort dei valori key.

### Strutture hash
Garantisce accesso diretto ed efficente ai dati basato sul valore del campo key.

Non conveniente per query di intervallo.

### Bitmap index
Basato su **matrice di bit**.

Fa riferimento a righe di dati attraverso **RID** (*row identifiers*).

La matrice di bit ha una colonna per ogni possibile valore dell'attributo indicizzato e una riga per ogni tupla.
Ad ogni cella il valore può essere 1 o 0, se la tupla assume il valore della colonna o no.

## Ottimizzazione delle operazioni
### Where
Sfrutta se possibile *accessi indicizzati*:
- **B+-tree**, **hash** o **bitmap**
	- Indifferente per predicati di uguaglianza semplice.
	- Per predicati di *range* usare solo B+-Tree.
	- Per predicati di selettività limitata si usa **full table scan**.
		- Se disponibile considera bitmap.
		- Prima calcola intersezione delle bitmap o RIDs e poi leggi la tabella e valuta i predicati restanti.

In caso di **congiunzione**:
- Si sceglie prima il predicato *più selettivo* e poi si applicano gli altri.

In caso di **disgiunzione**
- L'accesso indicizzato può essere sfruttato solo se **tutti** i predicati hanno un *indice*.
- Altrimenti full table scan.

### Join
Cruciale per DBMS relazionali, diversi algoritmi di join.
- **Nested loop**
	- 2 loop nidificati leggono le tabelle. per ogni riga dell'outer table loop sull'inner table per abbinare
- **Merge scan**
	- Solo su tabelle *ordinate sull'attributo di join*, i puntatori per effettuare il join si muovono insieme, solo 2 scan.
- **Hash join**
	- Applica funzione di hash ad attributo di join. Utile solo se le tabelle coinvolte hanno già indici di hash sull'attributo di join.
- **Bitmapped join index**
	- Matrici di bit che pre-calcolano il join, una colonna per ogni RID della tabella A e una riga per ogni RID della tabella B.

### Group by
- **Sort based**
	- Sugli attributi di raggruppamento.
- **Hash based**
	- Funzione di hash su attributi di group by.

## Ottimizzatore Oracle
Un commento viene interpretato come **HINT** se è del tipo:
`/*+
Hint1
Hint2
*/`
### Metodo di accesso
FULL(table) = Forza full table scan.
INDEX(table indexName) = Index scan su questi indici.
NO_INDEX(table indexName) = Evita di usare questi indici.
INDEX_COMBINE(table IndexName) = Bitmap access path.
INDEX_FFS(table indexName1 indexName2) = Fast full index scan.
NO_INDEX_FFS(table indexName1 indexName2) = Evita fast full index scan.

### Operatori di join
USE_NL( table1, table2, …)
NO_USE_NL ( … )
USE_MERGE ( … )
NO_USE_MERGE ( … )
USE_HASH ( … )
NO_USE_HASH ( … )

ORDERED = Effettua il join sulle tabelle nell'ordine con cui compaiono nel FROM.
LEADING( table1 table2 …) = Assegna table1 come **outer table** e table2 come **inner table**.

## Processo di ottimizzazione
 1. Analisi delle tabelle
	- Definizione *statistiche* per ogni **attributo**.
		- cardinalità
		- min-max (considerando distribuzione uniforme)
		- numero valori distinti (considerando distribuzione uniforme)
		- cardinalità per un certo predicato di selezione
2. Ispezione istruzione SQL.
	- Definizione query tree (**algebra**) associato all'istruzione SQL
		- Query nidificate.
		- Ordine dei join, identifica quale **tabella pilota** (ruolo 1 in relazioni 1 a molti).
	- Valutazione delle cardinalità di:
		- Foglie.
		- Nodi intermedi.
		- Nodo finale.
		- => Separare i predicati che operano su attributi diversi.
3. Valutazione piano di esecuzione **senza** strutture accessorie
4. Valutazione di possibili strutture accessorie per ogni indice.

# Concorrenza
*Schedule* = sequenza di operazioni read/write che evita le anomalie.
*Schedule seriale* = prima di eseguire una transazione vengono eseguite tutte le operazioni di un'altra transazione.

uno schedule è corretto quando fornisce gli stessi risultati di una schedule seriale con le stesse transazioni
- la schedule è serializzabile

## Anomalie
- **Lost update**, una delle transazioni concorrenti viene persa.
- **Dirty read**, una transazione legge il valore in uno stato intermedio che non diventa mai *stabile* (permanente).
	- *Commit projection* = ipotesi per cui la schedule contiene solo transazioni che terminano in commit.
	- L'anomalia dirty read non viene gestita
- **Inconsistent read**, Una transazione legge 2 valori diversi dello stesso campo.
- **Ghost update**
	- **A** = Una transazione osserva solo in parte gli effetti di un'altra transazione
	- **B** = Una transazione ingora un inserimento.

 ## Equivalenze
 (grafo dei conflitti)
### View equivalence
- *reads-from*
	- $r(x)_i$ legge da $w(x)_j$ quando
		- $w(x)_j$ preccede $r(x)_i$ con j diverso da i
		- non ci sono $w(x)_k$ tra di loro
- *write finale*
	- $w(x)_i$ è un write finale se è l'ultimo write di x che appare nella schedule

Due schedule sono view-equivalent se hanno:
- Lo stesso insieme read-from
- Lo stesso insieme final write

Una schedule è view-serializable se è view-equivalent ad una schedule seriale della stessa trasazione (VSR).

### Conflict equivalence
- L'azione $A_i$ è in conflitto con $A_j$ se entrambe operano sullo stesso oggetto e almeno 1 delle 2 è una write
	- **read-write conflicts**
	- **write-write conflicts**
- 2 schedule sono conflict equivalent se
	- hanno lo stesso conflict set
	- ogni conflict pair è nello stesso ordine in entrambe le schedule

Una schedule è **conflict-serializable** (CSR) se è equivalente ad un'arbitraria schedule seriale con le stesse transazioni.

Viene utilizzato un grafo dei conflitti
- un nodo per ogni transazione
- un edge $T_i$ -> $T_j$ se
	- esiste almeno un conflitto tra azione $A_i$ in $T_i$ e $A_j$ in T_j
	- $A_i$ precede $A_j$
- se il grafo è aciclico allora è conflict serializable
- complessità lineare

CSR è un sottoinsieme di VSR
 
 ## Locking
 **Lock** = blocco di una risorsa che potrebbe prevenire l'accesso ad altre.
 
 ###  2-phase Locking
 Garantisce *serializzabilità* Primitive:
- **read lock**
- **write lock**
- **unlock**

Prima di un'operazione di lettura/scrittura, lock delle risorse, poi unlock.

Il **read lock** è condiviso tra diverse transazioni:
- si usa un contatore per contare quanti usano il read lock.

Il **write lock** è esclusivo:
- non compatibile con altri lock sugli stessi dati

| richiesta |             | stato risorsa                |              |
| --------- | ----------- | ---------------------------- | ------------ |
														|           | **Free**        | **R-Locked**                     | **W-locked**     | 
| R-lock    | ok/r-locked | ok/r-locked                  | no/w-locked  |
| W-lock    | ok/w-locked | no/r-locked                  | no/w-locked  |
| Unlock    | error       | ok/free senza altri r-locked | ok/free      |

Versione **strict**:
- Consente il rilascio del lock solo alla fine di una transazione (commit o rollback)
	- evita *dirty read*

 ### Locking gerarchico
Ottenuto a diversi livelli di granularità
- Tabella
- Gruppo di tuple
	- Partizione logica/fisica
- Singola tupla
- Singolo campo in una tupla

**Primitive**:
- shared lock = **sl**
- exclusive lock = **xl**
- intention of shared lock = **isl**
	- mostra l'intento di shared locking su un oggetto in un nodo gerarchico più basso
- intention of exlusive lock = **ixl**
	- analogo a isl, ma per exclusive lock
- shared lock with intention of exclusive lock = **sixl**
	- shared lock su oggetto corrente e intento di exclusive lock su uno o più oggetti in un nodo più basso

**Protocollo di richiesta**:
1. i lock sono sempre richiesti a partire dalla radice
2. i lock sono rilasciati iniziando dal nodo di granularità più bassa e risalendo l'albero
3. per richiedere un **sl** o **isl** sono necessari **isl** (o **ixl**) sul suo parent
4. per richiedere un **xl**, **ixl**, **sixl** sono necessari **ixl** o **sixl** sul suo nodo parent
 
 ### Predicate Locking
 - Il predicate locking blocca tutti i dati che soddisfano un certo predicato
	- Implementato attraverso *indici* di locking

**Tipi di transazione**
- read-write
- read only
	- bastano gli shared lock

 ## Reliability
 Implementa i seguenti comandi transazionali:
- begin transaction (B)
- commit work (C)
- rollback (A)

**Operazioni di UNDO**
insert O -> delete O
update O -> scrivi il BS di O
delete O -> scrivi il BS di O

**OPERAZIONI DI REDO**
insert O -> scrivi AS di O
update O -> scrivi AS di O
delete O -> delete O

undo(undo(action) = undo(action)

 ### Log file
 **Contenuto del Log file**
- Record di transazione
	- Delimitatori
		- begin B(T)
		- commit C(T)
		- rollback A(T)
	- Data modifications
		- insert I(T, O, AS)
		- delete D(T, O, BS)
		- update U(T, O, BS, AS)
		- T = transazione, O = oggetto, BS/AS = before/after state
- Record di sistema
	- dump
	- checkpoint CK(L)
		- con L = insieme di transazioni attive

#### Dump
- crea una copia completa del database
- al termine un dump record è scritto nel log
	- data e ora del dump
	- dispositivo di dump utilizzato

#### Checkpoint
- accelera il processo di ripristino
- durante il checkpoint il dbms scrive su disco le pagine delle transazioni che hanno effettuato il commit (in maniera sincrona) e scrive anche le transazioni attive
	- tutte le transazioni vengono salvate, dopo che il checkpoint è iniziato nessuna transazione può eseguire il commit
	- le pagine di transazioni concluse (commit o abort) vengono scritte in maniera sincrona sul disco (attraverso la primitiva FORCE)
	- al termine, un checkpoint record viene registrato nel log
		- contiene l'insieme di transazioni attive
		- scritto attraverso la primitiva FORCE

 ### Restart
 **system failure**
- problema software o interruzione di corrente
- causa la perdita del contenuto in memoria principale (buffer DBMS) ma non del disco (database e log)

**media failure**
- causato da problemi dei dispositivi che gestiscono la memoria secondaria
- causa la perdita del database ma non del log (salvato su memoria stabile)

**warm restart (system failure)**
1. legge a ritroso il log fino all'*ultimo checkpoint record*
2. individua le transazioni per cui effettuare redo o undo
	1. all'ultimo checkpoint 
		- **undo** = { transazioni attive al checkpoint }
		- **redo** = {}
	2. legge il log in avanti 
		- **undo** = aggiungi transazioni per cui è presente il *begin record*. 
		- **redo** = *sposta* le transazioni da undo a redo se trovi il rispettivo *commit record*.
	3. esegui undo e redo
3. data recovery
	1. il log è letto *a ritroso* dal momento del *failure* fino all'i*nizio della transazione più vecchia nella undo list*.
		1. le azioni delle transazioni nella *undo list* sono **undone**
		2. per *ogni transazione* il *begin record deve essere raggiunto*, anche se precede l'ultimo checkpoint
	2. lettura del log i*n avanti* dall'*inizio della transazione più vecchia* nella *redo list*
		1. le azioni delle transazioni nella redo list sono applicate al database
		2. per ogni transazione il punto di partenza è il suo begin record

 **cold restard (media failure)**
1. accedi all'ultimo *dump* per ripristinare la porzione danneggiata del database sul disco
2. inizia dall'*ultimo dump record*, leggi il log in avanti e **redo** di tutte le azioni sul database e le transazioni commit/rollback
3. esegui *warm restart*

# Architetture Distribuite
 ## 2-phase commit
 - 1 coordinatore = Transaction Manager (TM)
- Diversi Resource Manager (RM)

Ogni partecipante può assumere il ruolo di TM.
TM e RM hanno i propri log privati.

**Record di TM log**
- Prepare
	- Contiene le identità di tutti gli RM partecipanti alla transazione (node ID + process ID)
- Global commit/abort
	- Decisione finale sulla transazione
- Complete
	- Scritto al termine del protocollo

**Record di RM log**
- Ready
	- Il RM è pronto ad eseguire il commit della transazione
	- La decisione non può essere cambiata

### Fase 1
- Il **TM**
	- Scrive il *prepare* record nel log
	- Invia messaggio di *prepare* a tutti i RM
	- Imposta il timeout
- I **RM**
	- Aspettano per il messaggio di *prepare*
	- Una volta ricevuto:
		- Se in reliable state:
			- Scrive il *ready* record nel log
			- Invia messaggio di *ready* al TM
		- Altrimenti
			- Invia messaggio *not ready* al TM
			- Termina il protocollo
			- Effettua rollback globale
- Il **TM**
	- Colleziona i messagi da RM
	- Se riceve i *ready* da **tutti** i RM
		- *Global commit* nel record log
	- Se riceve uno o più *not ready* o scade il timeout
		- *Global abort* nel record log

### Fase 2
- Il **TM**
	- Invia decisioni globali agli RM
	- Imposta timeout
- I **RM**
	- Attendono le decisioni globali
	- Una volta ricevute:
		- *Commit/Abort* record nel log
		- Il database viene aggiornato
		- Messaggio *ACK* inviato al TM
- Il **TM**
	- Colleziona tutti i messaggi *ACK*
	- Se tutti gli ACK sono stati ricevuti
		- Il record *complete* è scritto nel log
	- Se scade il timeout e alcuni ACK mancano
		- Nuovo timeout
		- Decisione globale inviata ai RM che non hanno risposto
	- Ripeti finchè tutte le risposte non vengono ricevute

 ## Failures
### Failure di un RM
- Il warm restart viene modificato con un nuovo caso
	- Se l'ultimo record nel log per una transazione è ready allora la transazione non conosce la decisione globale del suo TM.
- Recovery
	- Ready List
		- Nuova lista di ID di transazioni in ready
	- Per tutte le transazioni nella ready list le decisioni globali sono chieste ai TM al restart
		- **Remote recovery request**

### Failure di un TM
- I messaggi che possono essere persi sono
	- Prepare (outgoing) durante la fase 1
	- Ready (ingoing) durante la fase 1
	- Global decision (outgoing) durante la fase 2
- Recovery
	- Se l'ultimo record nel log è *prepare*
		- *Global abort* scritto nel log e inviato a tutti i partecipanti.
	- Altrimenti REDO della fase 1

### Network failuires
- Problemi durante la fase 1 causano global abort
- Problemi durante la fase 2 causano la ripetizione della fase 2

 # NoSQL
 ## MongoDB
 Ogni **istanza** di mongoDB può gestire diversi **database**, a loro volta composi da un insieme di **collezioni** che a loro volta contengono un insieme di **documenti**.

`show databases` = comando per mostrare i database
`use <db-name>` = seleziona il database interessato
`show collections`
`db.<collezione>.<comando>`
`db.<collezione>.drop()`
`db.dropDatabase()`
`db.createCollection(<nome>, <opzioni>)`

 `db.<collezione>.insertOne({valori json})`
`db.<collezione>.insertMany([{}, {}])`

`db.people.deleteMany( { status: "D" } )` = specifica lista di condizioni.

`db.collection.updateOne({filtro}, $set: {update}, {opzioni})`
`db.collection.updateMany({filtro}, {update}, {opzioni})`

`db.<collezione>.find({condizioni}, {campi di interesse})`
- Condizioni (**WHERE**)
	- {field1: valore, field2.subfield1: valore}
- Campi di interesse (**SELECT**)
	- {field1: 0, field2: 1}
`db.<collezione>.findOne({condizioni}, {campi di interesse})`

Find restituisce un **cursore** che può essere usato per iterare sui risultati o come input della prossima operazione.
`cursor.sort({filed1: 1, field2: -1})`
- 1 = ordine crescente
- -1 = ordine decrescente 
`cursor.count()`
`cursor.forEach( function(myDoc){ /*funzione*/} )`
`cursor.limit()`
`cursor.max()`
`cursor.min()`
`cursor.pretty()`

### Condizioni
`field : { $gt : 25 }` = maggiore
`field : { $gte : 25 }` = maggiore o uguale
`field : { $lt : 25 }` = minore
`field : { $lte : 25 }` = minore o uguale
`field : { $ne : 25 }` = diverso
`field : { $or : [ {filed1: value}, {field2: value}] }` = or

### Aggregazione
 `db.collection.aggregate([$group, $match])`

**Gruppo**
``` json
[
	{
		$group: {
			_id: "$status",       // GROUP BY (e SELECT) STATUS
			total: {$sum: "$age"} // SELECT SUM(AGE)
		},
	},
	{
		$match: {
			total: { $gt: 1000 }   // HAVING total > 1000	
		}
	}
]
```

Esistono altri stage

 ## Elastic Search
 document oriented (json) search engine

index <-> tabella
cluster <-> database

### Query
- espressa in DSL(domain specific language)

ritorna tutti i documenti in tutti gli indici
``` dsl
POST /_search
{}
```

cerca su uno specifico indice o su diversi indici
``` dsl
POST index1,index2/_search
{}
```

match può essere usato sia per full text che per exact queries
``` dsl
POST departments/_search
{
	"query": {
		"match" : { "name" : "Jhon"}
	}
}
```

should = or
must = and
must_not = not

``` dsl
POST departments/_search
{
	"query": {
		"bool" : {
			"should" : [
				{ "match" : { "name" : "John"} },
				{ "match" : { "name" : "Mark"} }
			],
			"minimum_should_match" : 1,
			"must" : { 
				{ "match" : { "title" : "developer" } }
			}
			"must_not" : {
				{ "match" : { "lastname" : "Smith"} }
			}
		}
	}
}
```

#### Insert
``` dsl
POST /index/<id>
{
	JSON document
}
```

#### Delete
``` dsl
DELETE index_name/id
```


#### Update
- i documenti sono immutabili
- per aggiornare un documento bisogna re-idnicizzarlo
	- recupera il vecchio documento
	- modifica la copia
	- cancella il vecchio documento
	- indicizza il nuovo documento